# Simple working version for quick testing
FROM ubuntu:22.04

# Install runtime dependencies and build tools
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    pkg-config \
    nlohmann-json3-dev \
    libfmt-dev \
    curl \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Install a simple HTTP server using Python instead of C++
WORKDIR /app

# Create a simple Python server that mimics our C++ functionality
COPY <<EOF server.py
import json
import time
from http.server import HTTPServer, BaseHTTPRequestHandler
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrafficHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.handle_request()
    
    def do_POST(self):
        self.handle_request()
    
    def handle_request(self):
        start_time = time.time()
        
        # Log incoming request
        logger.info(f"ðŸ”µ INCOMING: {self.command} {self.path} from {self.client_address[0]}")
        
        # Read request body
        content_length = int(self.headers.get('Content-Length', 0))
        request_body = self.rfile.read(content_length).decode('utf-8') if content_length > 0 else ""
        
        if request_body:
            logger.info(f"ðŸ“¥ REQUEST BODY: {request_body}")
        
        # Prepare response
        response_data = {
            "message": "Traffic Processor Echo",
            "method": self.command,
            "path": self.path,
            "received_data": request_body,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Calculate processing time
        processing_time_ms = int((time.time() - start_time) * 1000)
        
        # Log traffic (simulate Kafka producer)
        traffic_log = {
            "account_id": "local-traffic-processor",
            "timestamp": int(time.time()),
            "request": {
                "method": self.command,
                "path": self.path,
                "headers": dict(self.headers),
                "body": request_body,
                "client_ip": self.client_address[0]
            },
            "response": {
                "status": 200,
                "body": json.dumps(response_data),
                "processing_time_ms": processing_time_ms
            }
        }
        
        logger.info(f"ðŸ“¦ KAFKA MESSAGE: {json.dumps(traffic_log, indent=2)}")
        
        # Send response
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        self.wfile.write(json.dumps(response_data).encode())
        
        # Log response sent
        logger.info(f"âœ… RESPONSE SENT: 200 OK in {processing_time_ms}ms")

if __name__ == '__main__':
    server = HTTPServer(('0.0.0.0', 8080), TrafficHandler)
    print("Traffic Processor running on http://0.0.0.0:8080")
    server.serve_forever()
EOF

# No environment variables needed - everything is hardcoded for local setup

EXPOSE 8080

CMD ["python3", "server.py"]
